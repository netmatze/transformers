{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d78c32b-b838-489d-aefd-9b0714f34cd6",
   "metadata": {},
   "source": [
    "## Create template for Sentiment Analysis\n",
    "\n",
    "https://github.com/bentrevett/pytorch-sentiment-analysis/blob/main/1%20-%20Neural%20Bag%20of%20Words.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c2df9ef-4901-43e2-bc15-92dc7c47d2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1257769-39ee-494c-86ee-1f814b5dff34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['text', 'label'],\n",
       "     num_rows: 25000\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['text', 'label'],\n",
       "     num_rows: 25000\n",
       " }))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = datasets.load_dataset(\"imdb\", split=[\"train\", \"test\"])\n",
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d4fb7b0-4f00-454b-8209-179a9ccb9c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2423b5f9d85c470b9e8e2ea8a963983e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programme\\anaconda\\envs\\custom_transformer\\Lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mathias\\.cache\\huggingface\\hub\\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50aee09114ad4cb193498d1a834cc0e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f72839aece4c17ab2b3eed4d1e7024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c52374993a643cdabf9342b63d585fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52246549036a4fb8b7e6854e74bbcfec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c79c71d55af4be1befdc28108c5b125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc0ccc9e17342309aa5d7aae407b146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 30522\n",
      "type(x_train) <class 'torch.Tensor'>\n",
      "type(x_train[0]) <class 'torch.Tensor'>\n",
      "type(x_test) <class 'torch.Tensor'>\n",
      "type(x_test[0]) <class 'torch.Tensor'>\n",
      "y_train.shape  torch.Size([25000])\n",
      "y_test.shape  torch.Size([25000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathias\\AppData\\Local\\Temp\\ipykernel_26924\\3074138392.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train = torch.tensor(y_train)\n",
      "C:\\Users\\mathias\\AppData\\Local\\Temp\\ipykernel_26924\\3074138392.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test = torch.tensor(y_test)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "max_length = 256\n",
    "\n",
    "# Load the IMDb dataset from Hugging Face\n",
    "imdb_dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# Convert the dataset to PyTorch format\n",
    "imdb_dataset.set_format(\"torch\")\n",
    "\n",
    "# Get the training and test datasets\n",
    "train_dataset = imdb_dataset[\"train\"]\n",
    "test_dataset = imdb_dataset[\"test\"]\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")  # Replace with your desired tokenizer\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    #return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, padding=True, max_length=maxlen)\n",
    "    #return tokenizer(examples[\"text\"], return_tensors=\"pt\", truncation=False, padding=True, max_length=maxlen)\n",
    "    return tokenizer(examples[\"text\"], padding='max_length', truncation=True, max_length=max_length) \n",
    "\n",
    "imdb_dataset = imdb_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "train_dataset = imdb_dataset[\"train\"]\n",
    "test_dataset = imdb_dataset[\"test\"]\n",
    "\n",
    "# Extract features (x) and labels (y) from the datasets\n",
    "x_train = train_dataset[\"input_ids\"]\n",
    "y_train = train_dataset[\"label\"]\n",
    "x_test = test_dataset[\"input_ids\"]\n",
    "y_test = test_dataset[\"label\"]\n",
    "\n",
    "# Convert labels to torch tensors\n",
    "y_train = torch.tensor(y_train)\n",
    "y_test = torch.tensor(y_test)\n",
    "\n",
    "vocab_size = len(tokenizer.vocab)\n",
    "print('Vocabulary size:', vocab_size)\n",
    "\n",
    "print(\"type(x_train)\",type(x_train))\n",
    "print(\"type(x_train[0])\",type(x_train[0]))\n",
    "print(\"type(x_test)\",type(x_test))\n",
    "print(\"type(x_test[0])\",type(x_test[0]))\n",
    "print(\"y_train.shape \",y_train.shape)\n",
    "print(\"y_test.shape \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1360404f-8268-4dd4-932c-1248f74d86db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25000, 256])\n",
      "torch.Size([25000, 256])\n",
      "torch.Size([25000])\n",
      "torch.Size([25000])\n"
     ]
    }
   ],
   "source": [
    "x_train_tensor = x_train\n",
    "x_test_tensor = x_test\n",
    "y_train_tensor = y_train\n",
    "y_test_tensor = y_test  # Output: torch.Size([3, 3])\n",
    "\n",
    "# Print the shape of the resulting tensor\n",
    "print(x_train_tensor.shape)  # Output: torch.Size([3, 3])\n",
    "print(x_test_tensor.shape)  # Output: torch.Size([3, 3])\n",
    "print(y_train_tensor.shape)  # Output: torch.Size([3, 3])\n",
    "print(y_test_tensor.shape)  # Output: torch.Size([3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3e3da52-5ffb-42aa-94e3-53da18b59b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bca6797bb0f406cab046ac170042d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 30522\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AutoTokenizer\n",
    "import collections\n",
    "\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "import tqdm\n",
    "\n",
    "max_length = 256\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Load the IMDb dataset from Hugging Face\n",
    "imdb_dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# Convert the dataset to PyTorch format\n",
    "imdb_dataset.set_format(\"torch\")\n",
    "\n",
    "# Get the training and test datasets\n",
    "train_dataset = imdb_dataset[\"train\"]\n",
    "test_dataset = imdb_dataset[\"test\"]\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")  # Replace with your desired tokenizer\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    #return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, padding=True, max_length=maxlen)\n",
    "    #return tokenizer(examples[\"text\"], return_tensors=\"pt\", truncation=False, padding=True, max_length=maxlen)\n",
    "    return tokenizer(examples[\"text\"], padding='max_length', truncation=True, max_length=max_length) \n",
    "\n",
    "imdb_dataset = imdb_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "train_dataset = imdb_dataset[\"train\"]\n",
    "test_dataset = imdb_dataset[\"test\"]\n",
    "\n",
    "vocab_size = len(tokenizer.vocab)\n",
    "print('Vocabulary size:', vocab_size)\n",
    "\n",
    "x_train = train_dataset[\"input_ids\"]\n",
    "y_train = train_dataset[\"label\"]\n",
    "x_test = test_dataset[\"input_ids\"]\n",
    "y_test = test_dataset[\"label\"]\n",
    "\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_data = TensorDataset(x_test, y_test)\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a24f54f-223d-4e84-92d6-84cdfb8d40b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBoW(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
    "\n",
    "    def forward(self, ids):\n",
    "        # ids = [batch size, seq len]\n",
    "        embedded = self.embedding(ids)\n",
    "        # embedded = [batch size, seq len, embedding dim]\n",
    "        pooled = embedded.mean(dim=1)\n",
    "        # pooled = [batch size, embedding dim]\n",
    "        prediction = self.fc(pooled)\n",
    "        # prediction = [batch size, output dim]\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f17b7e5-b519-44a6-849d-cb42b00d41bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "output_dim = 1\n",
    "\n",
    "model = NBoW(vocab_size, embedding_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49235ff3-e363-44c0-bcaa-7f7ebcad9422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 9,156,901 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f634fe3-793d-4c4d-bc7c-a80adbc315ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fbcb3a8-61e1-4b92-b714-e3f8ce7a0e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = model#.to(device)\n",
    "criterion = criterion#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0efb17f-ecab-481d-8f4d-e33c07dabbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(prediction, label):\n",
    "    index = 0\n",
    "    correct_predictions = 0\n",
    "    for item in prediction:\n",
    "        item_argmax = 0\n",
    "        if item < 0.0:\n",
    "            item_argmax = 0\n",
    "        else:\n",
    "            item_argmax = 1\n",
    "        if label[index] == item_argmax:\n",
    "            correct_predictions += 1        \n",
    "    #predicted_classes = prediction.argmax(dim=-1)\n",
    "    #print(predicted_classes)\n",
    "    #print(label)\n",
    "    #correct_predictions = predicted_classes.eq(label).sum()\n",
    "    #print(correct_predictions)\n",
    "    #accuracy = correct_predictions / batch_size\n",
    "    return correct_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2db5720-3ba2-47ee-b9dc-3fbd8cac507b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 0.59790104, Test Accuracy: 15.90920716\n",
      "Epoch: 2, Train Loss: 0.39274567, Test Accuracy: 16.39130435\n",
      "Epoch: 3, Train Loss: 0.30089114, Test Accuracy: 16.36956522\n",
      "Epoch: 4, Train Loss: 0.25263773, Test Accuracy: 16.35166240\n",
      "Epoch: 5, Train Loss: 0.21900813, Test Accuracy: 16.46547315\n",
      "Epoch: 6, Train Loss: 0.19262800, Test Accuracy: 16.44245524\n",
      "Epoch: 7, Train Loss: 0.17021100, Test Accuracy: 16.43606138\n",
      "Epoch: 8, Train Loss: 0.15207934, Test Accuracy: 16.32992327\n",
      "Epoch: 9, Train Loss: 0.13522388, Test Accuracy: 16.33887468\n",
      "Epoch: 10, Train Loss: 0.12088050, Test Accuracy: 16.44884910\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "metrics = collections.defaultdict(list)\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []    \n",
    "    for batch_idx, (input_ids, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        ids = input_ids#.to(device)\n",
    "        label = labels#.to(device)\n",
    "        prediction = model(ids)#.to(device)\n",
    "        prediction = prediction.squeeze(-1)\n",
    "        #print(prediction.shape)\n",
    "        label = label.to(torch.float32)\n",
    "        #print(label.shape)\n",
    "        #print(prediction.dtype)\n",
    "        #print(label.dtype)\n",
    "        loss = criterion(prediction, label)\n",
    "        accuracy = get_accuracy(prediction, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "        epoch_accs.append(accuracy)\n",
    "    epoch_losses = np.mean(epoch_losses)\n",
    "    epoch_accs = np.mean(epoch_accs)\n",
    "    metrics[\"train_losses\"].append(epoch_losses)\n",
    "    metrics[\"train_accs\"].append(epoch_accs)\n",
    "    print(f\"Epoch: {epoch + 1}, Train Loss: {epoch_losses:.8f}, Test Accuracy: {epoch_accs:.8f}\")\n",
    "    #, Train Accuracy: {epoch_accs} Test Loss: {test_loss:.8f}, Test Accuracy: {test_accuracy:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e34779-9655-4960-89e2-0e439c2215f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404aaa64-96b0-4bb7-b121-893f657caf99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1795e78d-58f4-4cad-853d-a7905b3f60a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1439f67-2faf-4364-9dee-0d95d45c794e",
   "metadata": {},
   "source": [
    "## Decoder Architekture with masked attention for mlmatzeGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8464839c-4da0-4d64-9b2f-e5e9e9c3b307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
