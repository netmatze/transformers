{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635ee7c6-3fc5-4094-9488-81d9036f1f41",
   "metadata": {},
   "source": [
    "## Natural Language Processing with Transformers (book)\n",
    "\n",
    "### https://www.oreilly.com/library/view/natural-language-processing/9781098136789/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fab75e-73c9-4369-aae6-88ef15e9b9fc",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42fd120c-b337-4ceb-9b82-aa1be10341b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'am', 'reading', 'a', 'book', 'now', '.', 'i', 'love', 'to', 'read', 'books', '!']\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "tokens = tokenizer(\"I am reading a book now. I love to read books!\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dbac82-fc50-4577-904b-081e592f30e3",
   "metadata": {},
   "source": [
    "### Stopword removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3203fdb1-bdf8-49c7-8fd3-4f366437ea68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mathias\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bf550a-607b-492b-9f15-bb791cc211e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "stop_words = set(stopwords.words('englisch'))\n",
    "filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e125bd4-5567-43a8-8767-38570438c414",
   "metadata": {},
   "source": [
    "### Sentiment analysis cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc76525f-42af-4d1e-b187-0ce955a5b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "class SentimentAnalysisCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.conv = nn.Conv1d(embedding_dim, embedding_dim, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(embedding_dim, 2)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text).permute(0, 2, 1)\n",
    "        conved = self.relu(self.conv(embedded))\n",
    "        conved = conved.mean(dim=2)\n",
    "        return self.linear(conved)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe76c420-2401-411e-9320-2abd0eb73d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programme\\anaconda\\envs\\custom_transformer\\Lib\\site-packages\\torchtext\\data\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'love', 'this', 'book', '.', 'i', 'do', 'not', 'like']\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "tokens = tokenizer(\"I love this book. I do not like\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "870c979d-fa92-43b0-9965-786b53153200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([71, 55, 7, 35, 75, 76, 1, 39, 98, 41, 88], 1)\n",
      "([46, 20, 41, 94, 54, 75, 41, 99, 5], 0)\n",
      "([67, 85, 65, 2, 47, 44], 1)\n",
      "([71, 56, 7, 62, 83, 75, 40, 42], 0)\n",
      "([96, 4, 9, 29, 13, 72, 28], 1)\n",
      "([71, 12, 7, 70, 75, 82], 0)\n",
      "([67, 30, 84, 29, 58, 75, 101], 1)\n",
      "([71, 99, 25, 26, 59, 49], 0)\n",
      "([86, 10, 75, 68, 93], 1)\n",
      "([71, 64, 7, 13, 18, 29, 0, 75, 97], 0)\n",
      "([46, 6, 41, 15, 75, 41, 79], 1)\n",
      "([71, 27, 7, 45, 75, 41, 8, 7, 19], 0)\n",
      "([96, 38, 55, 81, 80, 90, 100, 24, 78], 1)\n",
      "([71, 60, 7, 32, 75, 41, 17, 7, 53], 0)\n",
      "([96, 77, 23, 29, 41, 22], 1)\n",
      "([71, 87, 33, 43, 75, 41, 94, 26, 73], 0)\n",
      "([67, 31, 16, 2, 36, 14], 1)\n",
      "([71, 99, 7, 74, 75, 11, 100, 34], 0)\n",
      "([96, 91, 95, 69, 41, 51, 89], 1)\n",
      "([71, 57, 50, 26, 66, 75, 63], 0)\n",
      "([46, 21, 3, 56, 59, 48], 1)\n",
      "([46, 92, 61, 3, 56, 37, 52], 0)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Sample sentences and labels\n",
    "book_samples = [\n",
    "    (\"The story was captivating and kept me hooked until the end.\".split(), 1),\n",
    "    (\"I found the characters shallow and the plot predictable\".split(), 0),\n",
    "    (\"An absolute masterpiece with stunning visuals.\".split(), 1),\n",
    "    (\"The movie was too slow and quite boring.\".split(), 0),\n",
    "    (\"A beautiful portrayal of a complex character.\".split(), 1),\n",
    "    (\"The dialogue was unrealistic and forced.\".split(), 0),\n",
    "    (\"An inspiring tale of hope and perseverance.\".split(), 1),\n",
    "    (\"The plot twists were very predictable.\".split(), 0),\n",
    "    (\"Excellent direction and outstanding performances.\".split(), 1),\n",
    "    (\"The film was a waste of time and money.\".split(), 0),\n",
    "    (\"I loved the cinematography and the soundtrack.\".split(), 1),\n",
    "    (\"The acting was subpar and the script was weak.\".split(), 0),\n",
    "    (\"A heartwarming story that brought tears to my eyes.\".split(), 1),\n",
    "    (\"The pacing was off and the ending was disappointing.\".split(), 0),\n",
    "    (\"A brilliant adaptation of the novel.\".split(), 1),\n",
    "    (\"The humor fell flat and the characters were annoying.\".split(), 0),\n",
    "    (\"An epic journey with breathtaking scenery.\".split(), 1),\n",
    "    (\"The plot was convoluted and hard to follow.\".split(), 0),\n",
    "    (\"A moving performance by the lead actor.\".split(), 1),\n",
    "    (\"The special effects were overdone and distracting.\".split(), 0),\n",
    "    (\"I love this movie very much.\".split(), 1),\n",
    "    (\"I did not this movie like it.\".split(), 0)\n",
    "]\n",
    "\n",
    "# Create vocabulary and word-to-index mapping\n",
    "tokens = set()\n",
    "for sentence, _ in book_samples:\n",
    "    tokens.update(sentence)\n",
    "tokens = list(tokens)\n",
    "\n",
    "word_to_idx = {word: i for i, word in enumerate(tokens)}\n",
    "vocab_size = len(tokens)\n",
    "embedding_dim = 10\n",
    "\n",
    "# Convert sentences to indices and create tensors\n",
    "data = [\n",
    "    ([word_to_idx.get(w, 0) for w in sentence], label)\n",
    "    for sentence, label in book_samples\n",
    "]\n",
    "\n",
    "# Print the generated data\n",
    "for sample in data:\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c06ac28-b9dc-4b42-86dc-2516032b421e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train loss: 0.7039518356323242\n",
      "epoch: 1, train loss: 0.6948510408401489\n",
      "epoch: 2, train loss: 0.7034589052200317\n",
      "epoch: 3, train loss: 0.711990475654602\n",
      "epoch: 4, train loss: 0.71644127368927\n",
      "epoch: 5, train loss: 0.7185185551643372\n",
      "epoch: 6, train loss: 0.7192012071609497\n",
      "epoch: 7, train loss: 0.7194348573684692\n",
      "epoch: 8, train loss: 0.7194900512695312\n",
      "epoch: 9, train loss: 0.7194545865058899\n",
      "epoch: 10, train loss: 0.7194345593452454\n",
      "epoch: 11, train loss: 0.7195402979850769\n",
      "epoch: 12, train loss: 0.7195961475372314\n",
      "epoch: 13, train loss: 0.7196378707885742\n",
      "epoch: 14, train loss: 0.7196109294891357\n",
      "epoch: 15, train loss: 0.7196887731552124\n",
      "epoch: 16, train loss: 0.7194210290908813\n",
      "epoch: 17, train loss: 0.7196381092071533\n",
      "epoch: 18, train loss: 0.719740092754364\n",
      "epoch: 19, train loss: 0.7198074460029602\n",
      "epoch: 20, train loss: 0.7197638750076294\n",
      "epoch: 21, train loss: 0.7195072174072266\n",
      "epoch: 22, train loss: 0.7195144891738892\n",
      "epoch: 23, train loss: 0.7198120355606079\n",
      "epoch: 24, train loss: 0.7199511528015137\n",
      "epoch: 25, train loss: 0.7200425863265991\n",
      "epoch: 26, train loss: 0.7199738621711731\n",
      "epoch: 27, train loss: 0.7195621728897095\n",
      "epoch: 28, train loss: 0.7195978760719299\n",
      "epoch: 29, train loss: 0.7197644114494324\n"
     ]
    }
   ],
   "source": [
    "import torch.optim \n",
    "\n",
    "sentimentanalysis_model = SentimentAnalysisCNN(vocab_size, embedding_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(sentimentanalysis_model.parameters(), lr=0.1)\n",
    "\n",
    "epochs = 30\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for sentence, label in data:\n",
    "        sentimentanalysis_model.zero_grad()\n",
    "        sentence = torch.LongTensor([word_to_idx.get(w, 0) for w in sentence]).unsqueeze(0)\n",
    "        outputs = sentimentanalysis_model(sentence)\n",
    "        label = torch.LongTensor([int(label)])\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch: {epoch}, train loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca71fbc1-b1d9-4ef8-a1ce-116d6e625511",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = {word: i for i, word in enumerate(tokens)}\n",
    "vocab_size = len(tokens)\n",
    "embedding_dim = 10\n",
    "book_samples = [\n",
    "    (\"The story was captivating and kept me hooked until the end.\".split(), 1),\n",
    "    (\"I found the characters shallow and the plot predictable\".split(), 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c90eee4-64fc-4d7e-bbf2-5787ee6d4b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book Review: I love this movie\n",
      "Sentiment: Negative\n",
      "\n",
      "Book Review: I do not like this movie\n",
      "Sentiment: Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book_reviews = [\n",
    "    \"I love this movie\".split(),\n",
    "    \"I do not like this movie\".split()\n",
    "]\n",
    "for review in book_reviews:\n",
    "    # Convert the review words into tensor form\n",
    "    input_tensor = torch.LongTensor([word_to_idx.get(w, 0) for w in sentence]).unsqueeze(0)\n",
    "    #input_tensor = torch.LongTensor([word_to_idx[w] for w in review], dtype=torch.long).unsqueeze(0) \n",
    "    # Get the model's output\n",
    "    outputs = sentimentanalysis_model(input_tensor)\n",
    "    # Find the index of the most likely sentiment category\n",
    "    _, predicted_label = torch.max(outputs.data, 1)\n",
    "    # Convert the predicted label into a sentiment string\n",
    "    sentiment = \"Positive\" if predicted_label.item() == 1 else \"Negative\"\n",
    "    print(f\"Book Review: {' '.join(review)}\")\n",
    "    print(f\"Sentiment: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eac203-5e04-4536-b981-a8023cb77128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
